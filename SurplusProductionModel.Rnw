\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{makeidx}
\usepackage[french]{babel}
\usepackage{graphicx}
\usepackage{amsfonts,amsmath,amssymb,amsthm}
\usepackage{algorithm2e}
\usepackage{fullpage}
\usepackage{hyperref}
\newcommand{\Xbf}{\boldsymbol{X}}
\newcommand{\Ybf}{\boldsymbol{Y}}
\title{Mise en oeuvre du filtrage et lissage par méthodes particulaires sur un modèle de production de biomasse}
\author{MP Etienne et P. Gloaguen}
\date{30 Janvier 2017}
\begin{document}
\maketitle
\tableofcontents
\section{Présentation de la problématique} 
\subsection{Formalisme général}
On se place dans le cadre d'un modèle à espace d'états.\\
On note $n$ le nombre total d'observations, $\Ybf= Y_{0:n}=(Y_0, \ldots, Y_n)$ les observations et $\Xbf=X_{0:n}$ les variables non observées.\\ 
\\
Dans ce travail, on se consacre à un modèle classique  de dynamique de populations avec prélèvement s'écrit
\begin{align}
X_{i+1} &= \left( X_i + r X_i\left(1- \frac{X_i}{K}\right) - C_i \right) \exp(\varepsilon_{i+1}), \quad \varepsilon_i\overset{i.i.d}{\sim}\mathcal{N}\left(-\frac{\sigma^2}{2}, \sigma^2\right)\\
Y_i\vert X_i &= q X_i \exp(\nu_{i}), \quad \nu_i\overset{i.i.d}{\sim}\mathcal{N}\left(-\frac{\sigma^2}{2}, \sigma^2\right)
\end{align}
Les observations $\Ybf$ sont des indices d'abondance, la variable non observée $\Xbf$ est la biomasse réelle. De plus, on possède l'historique des captures $C_1,\dots C_n$, supposées observées sans erreur.\\
On note $g_{\theta}(X_i,.)$ la loi de $Y_i$ conditionnelement à $X_i$, on note $m_{\theta}(X_{i}, .)$ le noyau de  transition de $X_i$ vers $X_{i+1}$ et $\nu_{\theta}()$, la loi initiale de $X_0$.
L'inférence pour ce type de modèle est classiquement menée dans un cadre bayésien dans un logiciel type BUGS ou JAGS. Ce type de logiciel demande une intialisation cohérente des paramètres, ce qui peut être compliqué. Les algorithmes particulaires, peuvent permettre de construire cette initialisation.

Plus généralement, si on souhaite faire de l'estimation fréquentiste, les méthodes particulaires permettent de mettre en oeuvre un algorithme type Monte Carlo EM.


\subsection{Loi de filtrage}

$\Xbf$ est un processus Markovien non linéaire observé indirectement au travers de $\Ybf$. On appelle loi de filtrage la loi de $X_{0:k}\vert Y_{0:k}$. Supposons  les paramètres du modèle connus, la loi de filtrage est différente de la loi de $X_k$ puisque les $Y$ apportent de l'information sur l'état du processus $\Xbf$, autrement dit la connaissance de l'ensemble des indices d'abondance jusqu'à l'année $k$ donne une information sur l'état réel du stock à l'année $k$.

Dans des cas très particulier (modèle linéaire Gaussien), on peut obtenir une forme explicite de la loi de filtrage (c'est le filtre de Kalman) mais ça n'est en général pas le cas. L'idée des  méthodes de filtrage particulaires est d'approcher par un échantillon de particules issues de cette loi.
La loi continue de $X_k$ va donc être approchée par une loi discrète, à valeurs dans un ensemble de particules $\xi_k^1,\dots,\xi_k^N$, associé à un ensemble de poids $\omega_k^1,\dots,\omega_k^N$ (avec la contrainte naturelle $\sum_{i=1}^N \omega_k^i =1$). 
Ainsi, pour toute fonction $f$, un estimateur de $\mathbb{E}(f(X_k)\vert Y_{1:k})$ sera donné par $$\sum_{i=1}^N \omega_k^if(\xi_{k}^i)$$

Afin de générer les couples $(\xi_k^i,\omega_k^i)$, on utilise des méthodes itératives. On commence par générer un échantillon approximation de la loi de  $X_1\vert Y_1$ et on va le propager pour obtenir un échantillon approchant la loi de $X_2\vert Y_{1:2}$, etc ....
%
\subsection{Loi de lissage}
Si on a accès à l'ensemble des indices d'abondance jusqu'à l'année $n$, et que le but est de pouvoir utiliser au mieux cette information on va avoir envie d'utiliser la loi de lissage, c'est à dire la loi de $X_k\vert Y_{1:n}$ ou si on veut reconstruire les historiques de biomasses les plus probables, on peut vouloir des lois jointes du type $X_{k_1:k_2}\vert Y_{1:n}$.
%
Les méthodes particulaires peuvent être utilisées également pour obtenir des réalisations de ces lois. Après avoir obtenu les lois de filtrage jusqu'à l'instant $n$, on va pouvoir utiliser d'autres algorithmes pour obtenir des  échantillons de particules issus des lois de lissage.
%

\section{Mise en oeuvre d'un algorithme particulaire pour obtenir la loi de filtrage}
%
\subsection{Rappel Importance sampling}
Pour obtenir un échantillon issu d'une loi cible $f$ qu'on ne sait pas simuler, il est possible d'utiliser une loi instrumentale $g$ de la manière suivante.

\begin{algorithm}
\For{ i in 1:G}{
  Draw $Z_i\sim g(.)$\;
  Compute weight $w_i=f(Z_i)/g(Z_i)$\;
}
Compute $w_+=\sum_{i=1}^G w_i$\;
Define normalized weight $\tilde{w}_i=w_i/w_+$\;
\caption{Importance Sampling algorithm}
\end{algorithm}
% 
% 
On peut aussi ajouter une étape de resampling pour avoir un échantillon non pondéré
\begin{algorithm}
\For{ i in 1:G}{
  Draw $Z_i\sim g(.)$\;
  Compute weight $w_i=f(Z_i)/g(Z_i)$\;
}
Compute $w_+=\sum_{i=1}^G w_i$\;
Define normalized weight $\tilde{w}_i=w_i/w_+$\;
\For{ i in 1:G}{
  Sample $I_i$ in $\left\lbrace 1, \ldots,G\right\rbrace$ such that $P(I_i=j)=\tilde{W}_j$
  Define $\tilde{Z}_i= Z_{I_i}$
}
\caption{Importance Sampling-Resampling algorithm}
\end{algorithm}
% 
% 
\subsection{Importance sampling séquentiel}
L'idée d'un filtrage particulaire est d'itérer ce processus d'importance sampling resampling pour obtenir des échantillons de la loi cible.

Il faut avoir une loi instrumentale $R(x, x')$ qui permet de propager une particule dans l'état $x$ à un instant donné vers une particule dans l'état $x\prime$ au temps suivant.
Si on dispose au temps $k$ d'un échantillon de la loi de filtrage, l'idée est de propager cet échantillon avec ce noyau $R$ et de pondérer chaque particule de manière appropriée.
Si on s'intéresse à la loi de $X_{k+1}\vert X_k, Y_{k+1}$, on peut écrire
\begin{align*}
[X_{k+1}\vert X_k, Y_{1:k+1}] = & \frac{[X_{k+1} X_k, Y_{1:k+1}]}{[ X_k, Y_{1:k+1}]}\\
&= \frac{[Y_{k+1}\vert X_{k+1}][X_{k+1} \vert X_k][X_{k}\vert Y_{1:k}]}{[ X_k, Y_{1:k+1}]}\\
&\propto \frac{[Y_{k+1}\vert X_{k+1}][X_{k+1} \vert X_k][X_{k}\vert Y_{1:k}]}{[ X_k, Y_{1:k+1}]}\\
&\propto \frac{g(X_{k+1}, Y_{k+1}) m( X_k, X_{k+1})[X_{k}\vert Y_{1:k}]}{[ X_k, Y_{1:k+1}]}
\end{align*}


\begin{algorithm}
\For{ i in 1:G}{
  Simuler $X_0^i \sim r_0$\;
  Calculer $w_0^i=\nu(X_0^i)/r_0(X_0^i)$\;
}
\For{ k in 1:n}{
  \For{ i in 1:G}{
  Simuler $X_k^i \sim R_k(X_{k-1}^i,.)$\;
  Calculer $w_k^i=w_{k-1}^i \frac{m_{\theta}(X_{k-1}^i, X_k^i) g(X_k^i,Y_k)}{ R_k(X_{k-1}^i,X_{k}^i) }$\;
  }
}
\caption{Particle filter algorithm 1}
\end{algorithm}

\section{Application}
\subsection{Simulation du modèle de production de biomasse}
Le code de simulation du modèle est le suivant
<<modelsimulation>>=
# Population Dynamic model simulation ----------------------------------
rm(list=ls()); set.seed(15);par(mfrow=c(1,1))
nYear <- 30
biomass <- rep(NA, nYear);capt <- rep(NA, nYear)
K <- 300 ## Capacité d'accueil
r <- 1.02 ## Taux de recrutement
q <- 0.5 #Capturabilité
sigmaBiomass <- 0.3
biomass[1] <- rnorm(1, mean=0.9*K, sd=K/10)
capt[1] <- runif(1,0.1,0.5)*biomass[1]
for( year in 2:nYear){
 Bk = biomass[year-1]
 capt[year-1] <- runif(1,0.1,0.5)*Bk
 #Les captures sont une fraction aléatoire de la biomasse
 innov <- rnorm(1, mean=-sigmaBiomass^2/2,sd=sigmaBiomass)
 biomass[year] <- (Bk+r*Bk*(1- Bk/K)-capt[year-1])*exp(innov)
 capt[year] <- runif(1,0.1,0.5)*biomass[year]
}
obs_error <- rnorm(nYear, mean=-sigmaBiomass^2/2, sd=sigmaBiomass)
abundanceIndex <- q * biomass*exp(obs_error)
#Calcul de la fenêtre des possible pour les Xs
sqrtD <- sqrt((1+r)^2-4*capt*r/K)
M0s <- (-(1+r)-sqrtD)/(-2*r/K)
m0s <- (-(1+r)+sqrtD)/(-2*r/K)
bounds <- cbind(m0s,M0s)
@
La figure \ref{fig:obs} représente les indices d'abondance, les captures, la biomasse réelle non observée, ainsi que les frontières possibles pour celle ci au vu du modèle dynamique.
\begin{figure}[p]
\centering
<<plotmodel,echo=FALSE,fig.height=5,fig.width=6>>=
par(mfrow=c(1,1))
plot(1:nYear,biomass, ylim=range(c(0,range(biomass),range(bounds))),
    main='Evolution de la biomasse',xlab="Année",type="b",pch=20,
    ylab="Masse",bty="n")
lines(1:(nYear),capt,type="b",col="red",pch=20)
legend("topright",pch=20,col=c("black","red"),
      legend = c("Biomasse","Captures"),
      bty="n",horiz = T)
lines(1:nYear, abundanceIndex, type='b',col="blue",pch=18,
     ylim=range(c(0,range(abundanceIndex))))
axis(side=4,at=pretty(range(abundanceIndex),n = 2),col = "blue",
    col.ticks = "blue",labels=F ,lwd.ticks=0)
mtext(side=4,text = "Indice d'abondance",col = "blue",at=150,line=1)
mtext(side=4,text = pretty(range(abundanceIndex),n=2),col = "blue",
     at=pretty(range(abundanceIndex),n=2))
matplot(bounds,lty=2,col="darkgrey",add=T,type="l")
@
\caption{Tracé des indices d'abondance et des captures. La biomasse réelle, non observée est tracée en noir. Les délimitations grises donne les frontières des possibles pour la biomasse si celle ci suit le modèle dynamique proposé.}
\label{fig:obs}
\end{figure}
\subsection{Implémentation du modèle}
Commençons par coder les fonctions spécifiques du modèle, nécessaires au calcul des poids:
<<fonction_mg>>=
mtheta<- function(x_old,x_new, capt_old,theta){
 r =theta$r; K=theta$K; sigmaBiomass = theta$sigmaBiomass;
 mn_innov =-sigmaBiomass^2/2
 dnorm(log(x_new),
       mean=log(x_old+r*x_old*(1-x_old/K)- capt_old)-mn_innov,
       sd=sigmaBiomass)
}
g<-function(x,y,theta){
 q =theta$q;sigmaBiomass=theta$sigmaBiomass;mn_innov =-sigmaBiomass^2/2
 dnorm(log(y), mean=log(q*x)-mn_innov,sd=sigmaBiomass)
}
@

\subsection{Implémentation des lois de propositions}
Il s'agit ensuite de définir une loi de proposition.\\
Ce choix est essentiel, et s'il n'a pas d'influence en théorie, il aura une grande importance en pratique.
De manière générale, il est souvent préférable que la loi de proposition soit flexible (donc explore bien l'espace des possibles) et dépende des observations.
Dans l'exemple considéré ici, à l'étape $k$, on doit proposer différentes valeurs $\xi_k^i,~i=1,\dots,G$ pour la biomasse réelle. Ces valeurs doivent évidement être positives, mais aussi cohérentes avec les données de capture. Ce qui veut dire que pour tout $i$, l'inégalité suivante doit être vérifiée
\begin{equation}
\xi_k^i+r\xi_k^i\left(1-\frac{\xi_k^i}{K}\right)>C_k
\label{eq:capt:cond}
\end{equation}
On peut vérifier que la condition \eqref{eq:capt:cond} est vérifiée si et seulement si:
\begin{align}
\Delta &: = (1+r)^2-4\frac{rC_k}{K}>0,\\
\text{Et, }~~& m_k:= -K\frac{-(1+r)+\sqrt{\Delta}}{2r} < \xi_k^i<M_k : =-K\frac{-(1+r)-\sqrt{\Delta}}{2r}\label{eq:def:bounds}
\end{align}

\subsubsection{Implémentation des lois initales}
Ainsi, pour $k=0$, un choix possible de génération des particules est celui d'une loi Gaussienne tronquée, dépendant des observations $Y_0$ et $C_0$:
\begin{align}
\log \xi_0^i&\overset{i.i.d}{\sim} f_0\\
\text{Avec } f_0(x)&=\left\lbrace \begin{array}{lr}
\frac{\varphi_0(x)}{\int_{m_0}^{M_0 }\varphi_0(s)ds} & \text{si } m_0<\exp(x)<M_0\\
0&\text{sinon}
\end{array}\right.\label{eq:def:f0}
\end{align}
où $m_0$ et $M_0$ sont définis par l'équation \eqref{eq:def:bounds} et  $\varphi_0$ est la densité d'une loi Gaussienne $\mathcal{N}(\mu_0,\sigma^2_0)$ de paramètres
\begin{align*}
\mu_0&= \log Y_0 - \log q + \frac{\sigma^2}{2}\\
\sigma^2_0 &= \sigma^2
\end{align*}
Il faut noter ici que d'autres paramètrisation de la loi normale sont possibles. On pourrait par exemple choisir une variance plus grande, ou une moyenne ne dépendant pas de $Y_0$.
Les fonction de génération et la densité associées à l'équation \eqref{eq:def:f0} sont codées ci dessous:
<<f0>>=
#Fonction de génération
rf0 <- function(G, theta,Y0=NA,C0=NA){
   #Extraction des paramètres nécessaires
   r =theta$r; sigmaBiomass = theta$sigmaBiomass;q=theta$q;
   mn_innov = -sigmaBiomass^2/2;#Pourrait être défini autrement
   Delta <- (1+r)^2-4*C0*r/K
   sqrtD <- sqrt(Delta)
   M0 <- (-(1+r)-sqrtD)/(-2*r/K)
   m0 <- (-(1+r)+sqrtD)/(-2*r/K)
   X0 <- sapply(1:G,function(i){
     ok <- F
     while(!ok){#On simule jusqu'à tomber dans la zone
       #acceptable au vu des captures
       cand <- exp(rnorm(1,log(Y0)-log(q)-mn_innov,
                         sigmaBiomass))
       ok <- (cand < M0) & (cand>m0)
     }
     return(cand)
   })
   return(X0)
}
df0 <- function(x0, theta,Y0=NA,C0=NA){
 #Extraction des paramètres nécessaires
 r =theta$r; sigmaBiomass = theta$sigmaBiomass;q=theta$q;
 mn_innov = -sigmaBiomass^2/2;#Pourrait être défini autrement
 Delta <- (1+r)^2-4*C0*r/K
 sqrtD <- sqrt(Delta)
 M0 <- (-(1+r)-sqrtD)/(-2*r/K)
 m0 <- (-(1+r)+sqrtD)/(-2*r/K)
 mn_ref <- log(Y0)-log(q)-mn_innov
 #Définition de la constante de normalisation
 norm_cst <- (pnorm(log(M0),mn_ref,sigmaBiomass)-
                pnorm(log(m0),mn_ref,sigmaBiomass))
 dx <- dnorm(log(x0),mn_ref,sigmaBiomass)/norm_cst
 return(dx)
}
@

\subsubsection{Implémentation des lois de proposition}
Il reste désormais à choisir une loi de proposition pour définir une particule $\xi_{k+1}^i$ à partir d'un parent $\xi_k^i$.
Il n'est pas nécessairement conseillé de prendre comme noyau de transition celui défini par le modèle. En effet, en pratique, le vrai jeu de paramètres n'est jamais connu. Pour un jeu de paramètres supposé, utiliser le noyau de transition du modèle peut alors être trop contraignant. Ainsi, on préfèrera ici une marche aléatoire autour des particules précédemment simulées, pondérée par l'observation $Y_{k+1}$\footnote{C'est exactement ici l'idée du filtre de Kalman}. Par exemple, si on considère une marche aléatoire Gaussienne sur le logarithme de la particule, et le processus d'observation, on a
\begin{align}
\log\xi_{k+1}^i\vert \log\xi_k^i& \sim \mathcal{N}(\log\xi_k^i,\sigma^2_{\text{RW}})
\intertext{Dans ce cas, on a alors}
\log \xi_{k+1}^i\vert \log\xi_k^i,\log Y_{k+1} &\sim \mathcal{N}(\mu_p,\sigma^2{p})\label{eq:prop:dist}
\intertext{Avec:}
\mu_p&= \sigma^2_p\left(\frac{\log \xi_{k}^i }{\sigma_{\text{RW}}^2} +\frac{\log Y_{k+1}^i -\log q +\sigma^2/2 }{\sigma^2}\right)\\
\sigma^2_p &= \frac{\sigma_{\text{RW}}^2+\sigma^2}{\sigma_{\text{RW}}^2\sigma^2}
\intertext{Comme pour le filtre de Kalman, cette loi se déduit de la décomposition}
p(\log \xi_{k+1}^i\vert \log\xi_k^i,\log Y_{k+1})&\propto p(\log\xi_{k+1}^i\vert\log \xi_k^i)p(\log Y_{k+1}\vert \log \xi_{k+1})
\end{align}
Encore une fois, si on veut prendre en compte les captures, il convient de tronquer la loi normale définie en \eqref{eq:prop:dist}, afin que pour tout $i$, $\xi_{k+1}^i$ satisfasse \eqref{eq:def:bounds}.

Le code résultant de ces distributions est donné par:
<<Propag>>=
rPropag <- function(x_old,theta,Y_new=NA,C_new=NA){
 sdRW = theta$sdRW; sigmaBiomass = theta$sigmaBiomass;
 mn_innov = -sigmaBiomass^2/2; q =theta$q;r=theta$r;
 K = theta$K;
 sqrtD <- sqrt((1+r)^2-4*C_new*r/K)
 M_new <- (-(1+r)-sqrtD)/(-2*r/K)
 m_new <- (-(1+r)+sqrtD)/(-2*r/K)
 v_gau  <- (sdRW^2*sigmaBiomass^2)/(sdRW^2+sigmaBiomass^2)
 mn2    <- log(Y_new)-log(q)-mn_innov
 mn_gau <- v_gau*(log(x_old)/(sdRW^2)+mn2/(sigmaBiomass^2))
 Xnex <- sapply(mn_gau,function(mn){
   ok <- F
   while(!ok){
     cand <- exp(rnorm(1,mn,sqrt(v_gau)))
     ok <- (cand > m_new) & (cand < M_new)
   }
   return(cand)
 })
 return(Xnex)
}
dPropag <- function(x_new, x_old,theta,Y_new=NA,C_new=NA){
 sdRW = theta$sdRW; sigmaBiomass = theta$sigmaBiomass;
 mn_innov = -sigmaBiomass^2/2; q =theta$q;r=theta$r;
 K = theta$K;
 sqrtD <- sqrt((1+r)^2-4*C_new*r/K)
 M_new <- (-(1+r)-sqrtD)/(-2*r/K)
 m_new <- (-(1+r)+sqrtD)/(-2*r/K)
 v_gau  <- (sdRW^2*sigmaBiomass^2)/(sdRW^2+sigmaBiomass^2)
 mn2    <- log(Y_new)-log(q)-mn_innov
 mn_gau <- v_gau*(log(x_old)/(sdRW^2)+mn2/(sigmaBiomass^2))
 dnex <- sapply(1:length(x_new),function(i){
   mn = mn_gau[i]
   (dnorm(log(x_new[i]),mn,sqrt(v_gau))
   /(pnorm(log(M_new),mn,sqrt(v_gau))-pnorm(log(m_new),mn,sqrt(v_gau))))
   #normalized by the area of possible zone
 })
 return(dnex)
}
@

\section{Un premier algorithme de filtrage}
On effectue un premier algorithme de filtrage:
<<first_filt>>=
#Initialisation
sdRW <- 10#Ecart type de la marche aleatoire
theta=list(q=q, K=K, sigmaBiomass=sigmaBiomass,
          r=r,sdRW=sdRW)#Paramètres pour la génération de particules
#et calculs de poids
G <- 30#Nombre de particules
Xs1 <- matrix(NA, ncol=nYear, nrow=G)#Particules
Xs1[,1] <- rf0(G=G,theta= theta,
            Y0 = abundanceIndex[1],C0 = capt[1] )
ws1 <- matrix(NA, ncol=nYear, nrow=G)#Poids
ws1[,1] <- df0(x0=Xs1[,1],theta = theta,
             Y0 = abundanceIndex[1],C0 = capt[1])
ws1[,1] <-  ws1[,1]/sum(ws1[,1])
for(year in 2:nYear){
 Xs1[,year] <- rPropag(x_old = Xs1[,year-1],theta = theta,
                       Y_new = abundanceIndex[year],
                       C_new = capt[year])#Génération de nvelles particules
 mth <- mtheta(x_old =Xs1[,year-1],x_new= Xs1[,year],
               theta= theta,capt_old=capt[year-1])
 #densité de transition du modele
 gfact <- g(Xs1[,year], abundanceIndex[year], theta)#Dnsité d'observation
 pfact <- dPropag(x_new = Xs1[,year],x_old= Xs1[,year-1],
                  theta = theta, Y_new = abundanceIndex[year],
                  C_new = capt[year])#Densité de la loi de proposition
 ws1[,year]=ws1[,year-1]*(mth*gfact/pfact)#Actualisation des poids
 ws1[,year] <-   ws1[,year]/sum(ws1[,year])#Normalisation des poids
}
@
\noindent Le code ci dessus permet de généréer un ensemble de couples particules/poids pour chaque instant $k$. On peut ainsi avoir une estimation de la loi de $X_k\vert Y_{0:k}$ à l'aide de méthodes classiques non paramétriques. Dans l'estimation par noyaux, on peut indiquer la pondération des particules à l'aide de la commande \textbf{weights}, comme dans la ligne ci dessous:
<<com_density,eval=FALSE>>=
density(Xs1[,k],weights = ws1[,k])
@
\noindent Cette représentation est effectuée pour $k=10$ sur la figure \ref{fig:first:dens}.\\
Sur la figure \ref{fig:first:dens}, on peut voir que peu de points semblent contribuer à l'estimation de la densité. 
Cette intuition est confirmée sur la figure \ref{fig:first:ws} représentant l'évolution des poids de chaque particule avec le temps. 
La grande majorité des poids est presque nulle, et seules 3 particules semblent avoir un poids conséquent pour l'estimation de la loi de filtrage. 
\begin{figure}[p]
\centering
<<first_dens_filt,echo=F,fig.height=5,fig.width=6>>=
k=nYear-5#Indice à représenter
plot(density(Xs1[,k],weights = ws1[,k]),
    main=bquote(paste('Loi de filtrage de '*'X'[.(k)])),
    xlab="Biomasse",ylab="Densité")
abline(v=biomass[k],lty=2)
points(Xs1[,k],rep(0,G) ,col="green",
       cex=ws1[,k]/max(ws1[,k]),pch=20)
@
\caption{Estimation par méthode à noyau de la distribution de filtrage à partir des couples parictules/poids obtenus avec le premier algorithme. Chaque point sur l'axe $y=0$ représente la position d'une particule. La taille du point est relative à son poids. La plupart des poids sont très proches de 0.}
\label{fig:first:dens}
\end{figure}
\begin{figure}[p]
<<first_ws,echo=FALSE,fig.height=5,fig.width=6>>=
matplot(t(ws1),type="b",pch=20,xlab="Indice k",ylab="Poids",
       main="Evolution des poids de filtrage\n Cas sans resampling",
       lty=1)
@
\caption{Evolution des poids de filtrage pour le premier algorithme proposé. La grande majorité des particules ont un poids associé nul, et ne contribue donc aucunement à l'estimation.}
\label{fig:first:ws}
\end{figure}
Il y a dégénérécence des poids de filtrage.
Pour palier ce problème, on ajoute une étape de rééchantillonnage (resampling). À chaque étape, on duplique les particules ayant un "avenir prometteur".

\section{Filtrage avec rééchantillonnage}
Avant la génération de nouvelles particules, on retire les parents parmi les parents générés à l'étape précédente, selon leurs anciens poids.
<<dec_filt_run,echo=F>>=
Geneal <- matrix(NA, ncol=nYear, nrow=G)
Geneal[,1] <- 1:G
Xs2 <- matrix(NA, ncol=nYear, nrow=G)
Xs2[,1] <- rf0(G=G,theta= theta,
            Y0 = abundanceIndex[1],C0 = capt[1] )
ws2 <- matrix(NA, ncol=nYear, nrow=G)
ws2[,1] <- df0(x0=Xs2[,1],theta = theta,
                  Y0 = abundanceIndex[1],C0 = capt[1])
ws2[,1] <- ws2[,1]/sum(ws2[,1])
for(year in 2:nYear){
 inds_rspl <- sample(1:G,size=G,replace=T,
                     prob = ws2[,year-1])#Rééchantillonnage
 Gnew <- Geneal[inds_rspl,]
 Gnew[,nYear] <- 1:G
 Gnew[,year-1] <- inds_rspl
 Geneal <- Gnew
 Xs2[,year] <- rPropag(x_old = Xs2[inds_rspl,year-1],
                     theta = theta,
                     Y_new = abundanceIndex[year],
                     C_new = capt[year])
 mth <- mtheta(x_old =Xs2[inds_rspl,year-1],
               x_new= Xs2[,year],
               theta= theta,
               capt_old=capt[year-1])
 gfact <- g(Xs2[,year], abundanceIndex[year], theta)
 pfact <- dPropag(x_new = Xs2[,year],x_old= Xs2[inds_rspl,year-1],
                  theta = theta, Y_new = abundanceIndex[year],
                  C_new = capt[year])
 ws2[,year]=(mth*gfact/pfact)
 ws2[,year] <-   ws2[,year]/sum(ws2[,year])
}
@
%
<<sec_filt_show,eval=FALSE>>=
#Initialisation, identique à précédemment
for(year in 2:nYear){
 inds_rspl <- sample(1:G,size=G,replace=T,
                     prob = ws2[,year-1])#Rééchantillonnage
 Xs2[,year] <- rPropag(x_old = Xs2[inds_rspl,year-1],
                     theta = theta,
                     Y_new = abundanceIndex[year],
                     C_new = capt[year])
 mth <- mtheta(x_old =Xs2[inds_rspl,year-1],
               x_new= Xs2[,year],
               theta= theta,
               capt_old=capt[year-1])
 gfact <- g(Xs2[,year], abundanceIndex[year], theta)
 pfact <- dPropag(x_new = Xs2[,year],x_old= Xs2[inds_rspl,year-1],
                  theta = theta, Y_new = abundanceIndex[year],
                  C_new = capt[year])
 ws2[,year]=(mth*gfact/pfact)
 ws2[,year] <-   ws2[,year]/sum(ws2[,year])
}
@
\noindent Comme précédemment, on peut regarder l'estimation à densité obtenu à partir de ce filtre, et la contribution relative de chaque particule à cette estimation. Un exemple est montré sur la figure \ref{fig:sec:dens}. La répartition des poids le long de l'algorithme est représentée sur la figure \ref{fig:sec:ws}. Les poids sont bien plus uniformément répartis.\\
Sur la figure \ref{fig:sec:parts} est représentée la dynamique des particules simulées (et de leurs poids) 
\begin{figure}[p]
\centering
<<sec_dens,echo=F,fig.height=5,fig.width=6>>=
plot(density(Xs2[,k],weights = ws2[,k]),
    main=bquote(paste('Loi de filtrage de '*'X'[.(k)])),
    xlab="Biomasse",ylab="Densité")
abline(v=biomass[k],lty=2)
points(Xs2[,k],rep(0,G) ,col="green",
       cex=ws2[,k]/max(ws2[,k]),pch=20)
@
\caption{Estimation par méthode à noyau de la distribution de filtrage à partir des couples parictules/poids obtenus avec le deuxième algorithme, introduisant une phase de rééchantillonngae. Chaque point sur l'axe $y=0$ représente la position d'une particule. Cette fois ci les poids sont bien plus uniformément répartis, comme montré sur la figure \ref{fig:sec:ws}}
\label{fig:sec:dens}
\end{figure}
\begin{figure}[p]
\centering
<<sec_ws,echo=F,fig.height=5,fig.width=6>>=
matplot(t(ws2),type="b",pch=20,xlab="Indice k",ylab="Poids",
       main="Evolution des poids de filtrage\n Cas avec resampling")
@
\caption{Evolution des poids de filtrage pour le second algorithme, incluant une phase de rééchantillonnage. Les poids sont à peu près uniformément répartis.}
\label{fig:sec:ws}
\end{figure}
\begin{figure}[p]
\centering
<<sec_filt_plot,echo=F,fig.height=5,fig.width=6,message=FALSE,fig.show=T,results="hide">>=
plot(1:nYear,biomass, ylim=range(c(range(biomass),range(bounds))),
    main='Dynamique des particules simulées',
    xlab="Année",type="n",pch=20, ylab="Masse",bty="n")
matplot(bounds,lty=2,col="darkgrey",add=T,type="l")
sapply(1:nYear,function(year){
  points(rep(year,G), Xs2[,year],col="green",
         cex=ws2[,year]/max(ws2[,year]),pch=20)
})
lines(biomass,type="b",pch=20)
@
\caption{Représentation des particules générés par l'agorithme de filtrage avec rééchantillonnage. La taille des points est relative à leur importance.}
\label{fig:sec:parts}
\end{figure}
%%%
\section{Lissage particulaire}
Dans la partie précédente, nous avns approcher, pour tout $k$, la loi de $X_k\vert Y_{0:k}$. Intuitivement, on se doute que les observations $Y_{(k+1):n}$ non utilisées pourraient pourtant fournir une information sur la distribution de $X_k$. Ainsi, on va s'intéresser maintenant à la \textbf{loi de lissage} de $X_k$, à savoir celle de $X_k\vert Y_{0:n}$.

\subsection{Approche trajectorielle}

On note ici $\xi_{0:n}^i$ la $i$-ème trajectoire de particules générée avec sa généalogie par l'algorithme de filtrage. À chaque trajectoire est associé le poids de filtrage final $\omega_n^i$. On note $\xi_{0:n}^i(k)$ la valeur de la trajectoire à l'instant $k$.\\
La loi de lissage en $k$ peut alors etre approchée par l'ensemble des couples $(\xi_{0:n}^i(k),\omega_n^i)_{i=1,\dots,G}$.\\
\\
Lorsque qu'il n'y a pas de rééchantillonnage, cette trajectoire consiste en la succession des $\xi_k^i$, ainsi $\xi_{0:n}^i(k)=\xi_k^i$.
À partir de notre premier filtrage effectué plus haut, on peut donc obtenir ces trajectoires simulées directement, associée à leur poids. Ces trajectoires sont représentées sur la figure \ref{fig:first:part:traj}. Encore une fois, la dégénérescence des poids est telle que l'approximation de la loi de lissage va se faire avec un seul point, ce qui est très mauvais.\\
Dans le cas avec rééchantillonage $\xi_{0:n}^i(n-1)$ correspond au parent de la $i$-ème particule à l'instant $n$, celle qui l'a générée.
Ainsi, il faut garder la généalogie des rééchantillonnages afin d'approcher les distributions de lissage.
La matrice de généalogie doit donc être stocké.
Un problème se pose ici, illustré par la figure \ref{fig:sec:gen}.
À cause du  rééchantillonage, à chaque étape, un certain nombre de particules ne donne pas de descendants.
Le nombre de particules ne donnant pas de descendants sur 2 générations est encore plus petit, et ainsi de suite.
Ainsi, on voit que 13 particules seulement générées pour $k=28$ ont un descendant à $k=n=30$ (figure \ref{fig:sec:gen}).
Ce sont ces 13 particules qui permettront l'approche de la loi de lissage pour $k=28$. Ce nombre de particules ayant des descendants décroit rapidement quand on remonte dans le temps.
Ainsi, pour $k$ petit, on se retrouvera vite avec 1 seule particule pour approcher la loi de lissage.
\begin{figure}[p]
<<traj_first,echo=F,fig.height=5,fig.width=6>>=
cols=ws1[,nYear]/max(ws1[,nYear])
matplot(t(Xs1),type="l",lwd=cols,lty=1,
      xlab="Année",ylab="Masse",
      main="Trajectoires particulaires\n Cas sans rééchantillonnage")
rect(par("usr")[1],par("usr")[3],
    par("usr")[2],par("usr")[4],col="lightgray")
matplot(t(Xs1)[,order(cols)],add =T,
       type="l",lty=1,col=gray(1-cols[order(cols)]))
@
\caption{Représentation des trajectoires de particules pour le filtre sans rééchantillonnage. La couleur correspond au poids relatif de chaque trajectoire. Quand la trajectoire est blanche, son poids relatif est nul. Ici, une seule trajectoire contribuerait au calcul des lois de lissage.}
\label{fig:first:part:traj}
\end{figure}
\begin{figure}[p]
\centering
<<geneal,echo=F,fig.width=6,fig.height=6>>=
par(mfrow=c(4,1),mar=c(1,1,1,1))
matplot((nYear-2):nYear,ylab="",xlab="",xaxt="n",yaxt="n",col="black",
       t(Geneal)[(nYear-2):nYear,],lty=1,type="b",pch=20,xlim=c(1,nYear))
matplot((nYear-10):nYear,ylab="",xlab="",xaxt="n",yaxt="n",col="black",
       t(Geneal)[(nYear-10):nYear,],lty=1,type="b",pch=20,xlim=c(1,nYear))
matplot((nYear-20):nYear,ylab="",xlab="",xaxt="n",yaxt="n",col="black",
       t(Geneal)[(nYear-20):nYear,],lty=1,type="b",pch=20,xlim=c(1,nYear))
matplot((1):nYear,ylab="",xlab="",xaxt="n",yaxt="n",col="black",
       t(Geneal)[(1):nYear,],lty=1,type="b",pch=20,xlim=c(1,nYear))
@
\caption{Représentation des ancêtres des particules associées à la figure \ref{fig:sec:parts}. 
Les ancêtres de haut en bas sur 2, 10,20, 29 générations.\newline
On voit que toutes les particules finales ont un ancêtre commun, la diversité ne se créant qu'à la 8ème génération.\newline
Ainsi, pour $k=28$, la loi de lissage s'approchera grâce à 13 particules, puis 4 pour $k=20$, 3 pour $k=10$.
Pour $k\leq 7$ la loi de lissage ne s'approchera que grâce à une particule!}
\label{fig:sec:gen}
\end{figure}
\subsection{Approche par simulation "backward"}
Dans cette approche, on souhaite obtenir l'approximation d'une espérance de type: 
\begin{equation}
\mathbb{E}[f(X_{k:l})\vert Y_{0:n}]\label{eq:smooth:exp}.
\end{equation}
Pour ce faire,  on effectura $N$ simulations de trajectoires possible, notées $\{\xi_{0:n}^i\}_{i=1,\dots,N}$ et on approchera \eqref{eq:smooth:exp} par 
\begin{equation}
\frac{1}{N}\sum_{i=1}^{N} f\left(\xi_{0:n}^i(k:p)\right)
\end{equation}
L'idée de l'approche par simulation backward est de réutiliser l'ensemble des couples poids particules simulées lors du filtrage afin de simuler des trajectoires possibles.\\
La procédure est intuitive, pour un point d'arrivée $(\xi_n^i,\omega_n^i)$ correspondant à la particule $i$, on simule son géniteur en tirant selon une multinomiale de poids
\begin{equation}
\Lambda_{n-1}^{j,i} = \frac{\omega_{n-1}^j q(\xi_{n-1}^j,\xi_{n}^i )}{\sum_{\ell=1}^N\omega_{n-1}^\ell q(\xi_{n-1}^\ell,\xi_{n}^i)}
\label{eq:Lambdas}
\end{equation}
Aisni, le poids de chaque ancêtre est un compromis entre son poids de filtrage et la vraisemblance qu'il soit l'ancêtre du candidat considéré.\\ 
On répète cette procédure itérativement afin d'obtenir une trajectoire.\\
La fonction suivante permet la simulation
<<simbackward>>=
rbackward <- function(Xs,ws){
  n <- ncol(Xs)
  N <- length(ws[,n])
  traj <- rep(NA,n)
  inds <- rep(NA,n)
  inds[n] <- sample(1:N,size=1,prob = ws[,n])#Indice initial
  traj[n] <- Xs[inds[n],n]#Particule initiale
  for(i in (n-1):1){
    ms <- mtheta(Xs[,i],traj[i+1],
                 capt_old = capt[i],theta = theta)#Calcul des densités
    #de transition
    Lambdas = ws[,i]*ms/sum(ws[,i]*ms)#Calcul des poids
    inds[i] <- sample(1:N,size=1,prob = Lambdas)
    traj[i] <- Xs[inds[i],i]
  }
  c(list(traj=traj,inds=inds))
}
@
Les figures \ref{fig:back:sim:1traj} et \ref{fig:back:sim:alltraj} montre le mécanisme de simulation sur une trajectoire, et la simulations de 30 trajectoires.
\begin{figure}[p]
\centering
<<simu_Ntraj,echo=F,fig.height=5,fig.width=6,message=FALSE,fig.show=T,results="hide">>=
Xb <- replicate(1,rbackward(Xs2,ws2)$traj)
par(mfrow=c(3,1),mar=c(1,1,1,1))
foo <- function(lag,Inds,Xs){
  plot(rep(nYear,G),Xs2[,nYear],ylab="",xlab="",xaxt="n",yaxt="n",
     type="p",pch=20,xlim=c(1,nYear),col="lightgray",
     ylim=range(c(0,range(biomass),range(bounds))))
  sapply(1:lag,function(i){
    points(rep(nYear-i,G),Xs[,nYear-i],pch=20,col="lightgray")
  })
  matplot((nYear-lag):nYear,Inds[(nYear-lag):nYear,],
        add=T,lty=1,type="b",pch=20)
}
foo(1,Xb,Xs2)
foo(2,Xb,Xs2)
foo(29,Xb,Xs2)
@
\caption{Simulation d'une trajectoire avec l'algorithme de simulation backward. Les ancêtres sont calculés à l'aide des poids de l'équation \eqref{eq:Lambdas}}
\label{fig:back:sim:1traj}
\end{figure}
\begin{figure}
\centering
<<simu_alltraj,echo=F,fig.height=5,fig.width=6,message=FALSE,fig.show=T,results="hide">>=
Xb <- replicate(G,rbackward(Xs2,ws2)$traj)
par(mfrow=c(1,1),mar=c(1,1,1,1))
foo <- function(lag,Inds,Xs){
  plot(rep(nYear,G),Xs2[,nYear],ylab="",xlab="",xaxt="n",yaxt="n",
     type="p",pch=20,xlim=c(1,nYear),col="lightgray",
     ylim=range(c(0,range(biomass),range(bounds))))
  sapply(1:lag,function(i){
    points(rep(nYear-i,G),Xs[,nYear-i],pch=20,col="lightgray")
  })
  matplot((nYear-lag):nYear,Inds[(nYear-lag):nYear,],
        add=T,lty=1,type="b",pch=20)
}
foo(29,Xb,Xs2)
lines(biomass,lwd=3,col="red")
@
\caption{Smulation de 30 trajectoires grâce à l'algorithme de backward simulation. La vraie trajectoire des biomasses est en rouge.}
\label{fig:back:sim:alltraj}
\end{figure}
\end{document}